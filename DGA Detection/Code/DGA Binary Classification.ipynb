{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center> Domain Generation Algorithm (DGA) Analysis - DMD2018 - CNN </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=1.png width=600px/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337) \n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import CSVLogger\n",
    "import keras\n",
    "import keras.preprocessing.text\n",
    "import itertools\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from keras import callbacks\n",
    "from keras.layers import Convolution1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabels = pd.read_csv('dgcorrect/trainlabel.csv', header=None)\n",
    "\n",
    "trainlabel = trainlabels.iloc[:,0:1]\n",
    "\n",
    "testlabels = pd.read_csv('dgcorrect/test1label.csv', header=None)\n",
    "\n",
    "testlabel = testlabels.iloc[:,0:1]\n",
    "\n",
    "testlabels1 = pd.read_csv('dgcorrect/test2label.csv', header=None)\n",
    "\n",
    "testlabel1 = testlabels1.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dgcorrect/train.txt', header=None)\n",
    "test = pd.read_csv('dgcorrect/test1.txt', header=None)\n",
    "test1 = pd.read_csv('dgcorrect/test2.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.values.tolist()\n",
    "X = list(itertools.chain(*X))\n",
    "\n",
    "\n",
    "T = test.values.tolist()\n",
    "T = list(itertools.chain(*T))\n",
    "\n",
    "T1 = test1.values.tolist()\n",
    "T1 = list(itertools.chain(*T1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n"
     ]
    }
   ],
   "source": [
    "# Generate a dictionary of valid characters\n",
    "valid_chars = {x:idx+1 for idx, x in enumerate(set(''.join(X+T+T1)))}\n",
    "\n",
    "max_features = len(valid_chars) + 1\n",
    "\n",
    "maxlen = np.max([len(x) for x in X])\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert characters to int and pad\n",
    "X1 = [[valid_chars[y] for y in x] for x in X]\n",
    "\n",
    "T11 = [[valid_chars[y] for y in x] for x in T]\n",
    "\n",
    "T12 = [[valid_chars[y] for y in x] for x in T1]\n",
    "\n",
    "X_train = sequence.pad_sequences(X1, maxlen=maxlen)\n",
    "\n",
    "X_test = sequence.pad_sequences(T11, maxlen=maxlen)\n",
    "\n",
    "X_test1 = sequence.pad_sequences(T12, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(trainlabel)\n",
    "y_test = np.array(testlabel)\n",
    "y_test1 = np.array(testlabel1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sriram\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=32, kernel_size=3, strides=1, padding=\"valid\")`\n",
      "  \n",
      "c:\\users\\sriram\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "790739/790739 [==============================] - 604s 763us/step - loss: 0.0825 - acc: 0.9688\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.08250, saving model to checkpoint-01.hdf5\n"
     ]
    }
   ],
   "source": [
    "no_of_epochs = 1\n",
    "batch_size = 32\n",
    "hidden_dims=128\n",
    "nb_filter = 32\n",
    "filter_length =3 \n",
    "embedding_vecor_length = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_vecor_length, input_length=maxlen))\n",
    "model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length,\n",
    "                        border_mode='valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length=1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='loss')\n",
    "csv_logger = CSVLogger('training_set_lstmanalysis.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=no_of_epochs,shuffle=True,callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"coomplemodel.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2457407/2457407 [==============================] - 539s 220us/step\n",
      "Test score: 0.047620250878603575\n",
      "Test accuracy: 0.9820782637959442\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2922/2922 [==============================] - 1s 223us/step\n",
      "Test score: 1.265687407898952\n",
      "Test accuracy: 0.7186858316221766\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test1, y_test1, batch_size=32)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
